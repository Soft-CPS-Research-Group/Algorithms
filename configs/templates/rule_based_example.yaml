# Example configuration for running a rule-based baseline inside the same
# orchestration environment. The schema mirrors the MADDPG layout so it can be
# validated and tracked consistently, even though many parameters are unused.
metadata:
  experiment_name: "rule_based_demo"
  run_name: "Rule Based Baseline"

runtime:
  log_dir: null
  mlflow_uri: null

tracking:
  mlflow_enabled: true
  log_level: "INFO"

checkpointing:
  resume_training: false
  checkpoint_run_id: null
  checkpoint_artifact: "rule_based_checkpoint.json"
  use_best_checkpoint_artifact: false
  reset_replay_buffer: false
  freeze_pretrained_layers: false
  fine_tune: false
  checkpoint_interval: null

simulator:
  dataset_name: citylearn_challenge_2022_phase_all_plus_evs
  dataset_path: ./datasets/citylearn_challenge_2022_phase_all_plus_evs/schema.json
  central_agent: false
  reward_function: RewardFunction

training:
  seed: 22
  end_initial_exploration_time_step: 0
  end_exploration_time_step: 0
  steps_between_training_updates: 1
  target_update_interval: 0

topology:
  num_agents: null
  observation_dimensions: null
  action_dimensions: null
  action_space: null

algorithm:
  name: "RuleBasedPolicy"
  hyperparameters:
    gamma: 1.0
  networks: null
  replay_buffer: null
  exploration: null
