experiment:
  name: "citylearn_dataset"
  run_name: "Run 0 - Testing if everything works"
  logging:
    log_dir: "./logs"  # Directory for log files
    log_level: "DEBUG"  # Logging level
    mlflow: true  # Enable MLflow
    mlflow_uri: "file:./mlruns"  # MLflow tracking URI

simulator:
  dataset_name: citylearn_challenge_2022_phase_all_plus_evs
  dataset_path: ./datasets/citylearn_challenge_2022_phase_all_plus_evs/schema.json         
  central_agent: false                    
  reward_function: RewardFunction

algorithm:
  seed: 22
  hyperparameters:
    checkpoint_interval: 20
    steps_between_training_updates: 5
    target_update_interval: 2
    end_exploration_time_step: 200
    end_initial_exploration_time_step: 100
    num_agents:
    observation_dimensions:
    action_dimensions:
    action_space:
    gamma: 0.99
  networks:
    actor_network:
      class: "Actor"
      params:
        layers: [ 256, 128 ]
        lr: 1e-4
        optimizer_class: "Adam"
    critic_network:
      class: "Critic"
      params:
        layers: [ 256, 128 ]
        optimizer_class: "Adam"
        lr: 1e-3
  replay_buffer:
    class: "MultiAgentReplayBuffer"
    params:
      "capacity": 100000,
      "batch_size": 256
  exploration:
    strategy: "GaussianNoise"
    params:
      bias: 0.3
      sigma: 0.2
      decay: 0.995
      gamma: 0.99
      tau: 0.001




