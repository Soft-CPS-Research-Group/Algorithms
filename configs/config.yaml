experiment:
  name: "real_world_dataset_4houses"
  run_name: "Run 6 - Final Testing Run"
  resume_training: false
  checkpoint_run_id: "1234567890abcdef"  # Paste the correct run_id here
  checkpoint_artifact: "latest_checkpoint.pth"
  use_best_checkpoint_artifact: false
  reset_replay_buffer: false  # If true, clears replay buffer when loading checkpoint
  freeze_pretrained_layers: false
  save_checkpoints: true
  checkpoint_interval_steps: 5000
  save_final_model: true
  logging:
    log_dir: "./logs"  # Directory for log files
    log_level: "DEBUG"  # Logging level
    mlflow: true  # Enable MLflow
    mlflow_uri: "file:./mlruns"  # MLflow tracking URI

simulator:
  dataset_name: citylearn_challenge_2022_phase_all_plus_evs
  dataset_path: ./datasets/citylearn_challenge_2022_phase_all_plus_evs/schema.json         
  central_agent: false                    
  reward_function: RewardFunction

algorithm:
  seed: 22
  hyperparameters:
    checkpoint_interval: 20
    steps_between_training_updates: 5
    target_update_interval: 2
    end_exploration_time_step: 200
    end_initial_exploration_time_step: 100
    num_agents:
    observation_dimensions:
    action_dimensions:
    action_space:
    gamma: 0.99
  networks:
    actor_network:
      class: "Actor"
      params:
        layers: [2048, 1024, 512, 256, 128, 64]
        lr: 1e-4
        optimizer_class: "Adam"
    critic_network:
      class: "Critic"
      params:
        layers: [2048, 1024, 512, 256, 128, 64]
        optimizer_class: "Adam"
        lr: 1e-3
  replay_buffer:
    class: "MultiAgentReplayBuffer"
    params:
      "capacity": 100000
      "batch_size": 512
  exploration:
    strategy: "GaussianNoise"
    params:
      bias: 0.3
      sigma: 0.2
      decay: 0.995
      gamma: 0.99
      tau: 0.001




